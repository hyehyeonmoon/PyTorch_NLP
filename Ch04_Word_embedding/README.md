## [Summary]

- 단어의 구조 및 의미에 대해서 배웠고, 이러한 것이 반영된 단어 사전 WordNet을 실습해 보았습니다.
- TF-IDF(딥러닝 이전의 단어임베딩)에 대해 배우고, 실습을 해보았습니다.
- 단어 유사도(거리)를 구하는 방식인 L1, L2, Inf norm, cosine similarity에 대해 배웠습니다.
- 단어임베딩의 원리와 Word2Vec, Glove, FastText 세 가지 유명한 임베딩을 배웠습니다.
- FastText 실습을 진행합니다.
- 실무에서는 pre-trained word embedding을 사용하지 않고 embedding layer를 사용합니다.

## [파일]

|File|Description|Folder|
|wordnet |wordnet 실습 |04-wordnet|
|word_similarity |L1, L2, Inf norm, Cosine similarity를 이용해 단어 유사도 구하기 실습 |07-previous_methods |
|fasttext |FastText를 불러와 단어임베딩 실습(Python code) |13-word_embedding |
|word_embedding_vector_exercise |FastText를 불러와 단어임베딩 실습(Mac) |13-word_embedding |

(FastText 실습의 경우, 강사님은 리눅스(?) 코드를 쓰셔서 비전공자는 이해하기가 힘들다. [https://rlagywns0213.github.io/nlp/NLP-fasttext0/](https://rlagywns0213.github.io/nlp/NLP-fasttext0/) 사이트를 참고하면 무리 없이 같은 실습을 더 쉽게 진행할 수 있다.)

## Reference

[김기현의 딥러닝을 활용한 자연어처리 입문 올인원 패키지 Online. | 패스트캠퍼스](https://www.fastcampus.co.kr/data_online_dpnlp)
